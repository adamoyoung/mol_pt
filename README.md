# Pretrained models for representing molecules


|Date|First Author|Title|Code|Conference/Journal|Representation|
|---|---|---|---|---|---|
|2021/01/01|Dongyu Xue|X-MOL: large-scale pre-training for molecular understanding and diverse molecular analysis|[paddle](https://github.com/bm2-lab/X-MOL)| [biorxiv](https://www.biorxiv.org/content/10.1101/2020.12.23.424259v2)|string|
|2020/10/19|Seyone Chithrananda|ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction|[pytorch](https://github.com/seyonechithrananda/bert-loves-chemistry)|[arxiv](https://arxiv.org/abs/2010.09885)|string|
|2021/06/17|Jinhua Zhu|Dual-view Molecule Pretraining|NA|[arxiv](https://arxiv.org/abs/2106.10234)|string,graph|
|2019/05/29|Weihua Hu|Strategies for Pre-training Graph Neural Networks|[pytorch](https://github.com/snap-stanford/pretrain-gnns/),[dgl-life](https://lifesci.dgl.ai/api/model.pretrain.html)|[ICLR2020](https://arxiv.org/abs/1905.12265)|graph|
|2020/06/18|Yu Rong|Self-Supervised Graph Transformer on Large-Scale Molecular Data (GROVER)|[pytorch](https://github.com/tencent-ailab/grover)|[NEURIPS2020](https://arxiv.org/abs/2007.02835)|graph|
|2020/10/18|HyunSeobKim|A Merged Molecular Representation Learning (Chem-BERT)|[pytorch](https://github.com/HyunSeobKim/CHEM-BERT)|NA|string|
|2020/02/19|Łukasz Maziarka|Molecule Attention Transformer|[pytorch](https://github.com/ardigen/MAT)|[arxiv](https://arxiv.org/abs/2002.08264)|graph|
|2019/11/12|Shion Honda|SMILES Transformer: Pre-trained Molecular Fingerprint for Low Data Drug Discovery|[pytorch](https://github.com/DSPsleeporg/smiles-transformer)|[arxiv](https://arxiv.org/abs/1911.04738)|string|
|2021/06/17|Jerret Ross|Do Large Scale Molecular Language Representations Capture Important Structural Information? (MolFormer)|NA|[arxiv](https://arxiv.org/abs/2106.09553)|string|
|2020/02/19|Łukasz Maziarka|Molecule Attention Transformer|[pytorch](https://github.com/ardigen/MAT),[pytorch](https://github.com/lucidrains/molecule-attention-transformer)|[arxiv](https://arxiv.org/abs/2002.08264)|string|


Format inspired by the [SegLoss repo by JunMa11](https://github.com/JunMa11/SegLoss)
